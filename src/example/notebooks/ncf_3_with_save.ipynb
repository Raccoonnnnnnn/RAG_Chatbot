{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7fb7e64-2945-41f5-b3f7-dbc8de6b4d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "958afd78-944f-4f2a-baa7-f72be32987a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_id  book_id  rating\n",
      "0    U054     1418       4\n",
      "1    U064      526       5\n",
      "2    U041      310       4\n",
      "3    U004     1015       4\n",
      "4    U028     1015       4\n"
     ]
    }
   ],
   "source": [
    "book_df = pd.read_csv('C:/Users/davin/Desktop/Fake Data/books_meta_sample.csv', on_bad_lines='skip', encoding=\"UTF-8\")\n",
    "book_df.columns = ['book_id', 'name', 'link', 'author']\n",
    "\n",
    "user_df = pd.read_csv('C:/Users/davin/Desktop/Fake Data/users.csv', on_bad_lines='skip', encoding=\"UTF-8\")\n",
    "user_df.columns = ['user_id', 'join_date', 'age', 'gender']\n",
    "\n",
    "rating_df = pd.read_csv('C:/Users/davin/Desktop/Fake Data/interactions.csv', on_bad_lines='skip', encoding=\"UTF-8\")\n",
    "rating_df.columns = ['user_id', 'book_id', 'rating','timestamp', 'review_length_chars', 'liked']\n",
    "\n",
    "cbr = pd.merge(rating_df, book_df, on='book_id')\n",
    "columns = ['link', 'author', 'timestamp', 'review_length_chars', 'liked', 'name']\n",
    "cbr = cbr.drop(columns, axis=1)\n",
    "print(cbr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b969c2-cc04-4f19-943a-3d6d5ded7dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_id  book_id  rating  user_idx  book_idx\n",
      "0    U054     1418       4        53       925\n",
      "1    U064      526       5        63       345\n",
      "2    U041      310       4        40       214\n",
      "3    U004     1015       4         3       667\n",
      "4    U028     1015       4        27       667\n"
     ]
    }
   ],
   "source": [
    "users = list(cbr['user_id'].unique())\n",
    "books = list(cbr['book_id'].unique())\n",
    "\n",
    "user2idx = {user: idx for idx, user in enumerate(users)}\n",
    "book2idx = {book: idx for idx, book in enumerate(books)}\n",
    "\n",
    "num_users = len(users)\n",
    "num_books = len(books)\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "book_encoder = LabelEncoder()\n",
    "\n",
    "cbr['user_idx'] = user_encoder.fit_transform(cbr['user_id'])\n",
    "cbr['book_idx'] = book_encoder.fit_transform(cbr['book_id'])\n",
    "\n",
    "print(cbr.head())\n",
    "\n",
    "# Chia train/test\n",
    "train_df, test_df = train_test_split(cbr, test_size=0.2, random_state=42)\n",
    "\n",
    "# Chuyển sang tensor\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(train_df['user_idx'].values, dtype=torch.long),\n",
    "    torch.tensor(train_df['book_idx'].values, dtype=torch.long),\n",
    "    torch.tensor(train_df['rating'].values, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor(test_df['user_idx'].values, dtype=torch.long),\n",
    "    torch.tensor(test_df['book_idx'].values, dtype=torch.long),\n",
    "    torch.tensor(test_df['rating'].values, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90e0cda1-5cc4-460b-8152-0b80564e182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_books, embedding_dim=32):\n",
    "        super(NCF, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.book_embedding = nn.Embedding(num_books, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim*2, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, user, book):\n",
    "        user_emb = self.user_embedding(user)\n",
    "        book_emb = self.book_embedding(book)\n",
    "        x = torch.cat([user_emb, book_emb], dim=-1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "num_users = len(users)\n",
    "num_books = len(books)\n",
    "\n",
    "model = NCF(num_users, num_books)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7659ef90-c4d5-46c0-b273-d154c4a0d3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Training Loss: 2.1608\n",
      "Epoch 2/20, Training Loss: 0.7782\n",
      "Epoch 3/20, Training Loss: 0.6922\n",
      "Epoch 4/20, Training Loss: 0.6378\n",
      "Epoch 5/20, Training Loss: 0.5987\n",
      "Epoch 6/20, Training Loss: 0.5710\n",
      "Epoch 7/20, Training Loss: 0.5502\n",
      "Epoch 8/20, Training Loss: 0.5380\n",
      "Epoch 9/20, Training Loss: 0.5185\n",
      "Epoch 10/20, Training Loss: 0.5101\n",
      "Epoch 11/20, Training Loss: 0.4861\n",
      "Epoch 12/20, Training Loss: 0.4739\n",
      "Epoch 13/20, Training Loss: 0.4604\n",
      "Epoch 14/20, Training Loss: 0.4488\n",
      "Epoch 15/20, Training Loss: 0.4370\n",
      "Epoch 16/20, Training Loss: 0.4298\n",
      "Epoch 17/20, Training Loss: 0.4352\n",
      "Epoch 18/20, Training Loss: 0.4223\n",
      "Epoch 19/20, Training Loss: 0.4189\n",
      "Epoch 20/20, Training Loss: 0.4111\n"
     ]
    }
   ],
   "source": [
    "epochs = 20  # bạn có thể tăng lên 50–100 nếu dữ liệu lớn\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for user_batch, book_batch, rating_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(user_batch, book_batch).squeeze()\n",
    "        loss = criterion(preds, rating_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96c794a8-4b92-4624-8c5f-be20521565aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user_id  book_id  rating  user_idx  book_idx  predicted_rating\n",
      "6408    U056     1069       5        55       707          5.101834\n",
      "7678    U084     1429       3        83       933          3.466252\n",
      "4843    U035     1914       4        34      1234          4.540919\n",
      "357     U014      151       4        13       105          4.624361\n",
      "3314    U094     1193       4        93       786          3.314741\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for user_batch, book_batch, rating_batch in test_loader:\n",
    "        preds = model(user_batch, book_batch).squeeze()\n",
    "        all_preds.extend(preds.tolist())\n",
    "        all_true.extend(rating_batch.tolist())\n",
    "\n",
    "# Chuyển sang DataFrame để xem\n",
    "test_results = test_df.copy()\n",
    "test_results['predicted_rating'] = all_preds\n",
    "print(test_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f951363f-6f83-4b7f-86f6-bd948917a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "def recommend_books_for_user(\n",
    "    user_id,\n",
    "    model,\n",
    "    user2idx,\n",
    "    book2idx,\n",
    "    ratings_df,      # DataFrame: user_id, book_id, rating\n",
    "    top_k=5,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "\n",
    "    # Kiểm tra user có tồn tại không\n",
    "    if user_id not in user2idx:\n",
    "        raise ValueError(f\"User {user_id} không tồn tại trong dữ liệu!\")\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Lấy index user\n",
    "    user_idx = user2idx[user_id]\n",
    "\n",
    "    # Danh sách tất cả sách trong hệ thống\n",
    "    all_book_ids = list(book2idx.keys())\n",
    "\n",
    "    # Sách user đã đọc\n",
    "    already_read = ratings_df[ratings_df[\"user_id\"] == user_id][\"book_id\"].values\n",
    "    unread_books = [b for b in all_book_ids if b not in already_read]\n",
    "\n",
    "    if len(unread_books) == 0:\n",
    "        return \"User này đã đọc hết sách!\"\n",
    "\n",
    "    unread_book_indices = [book2idx[b] for b in unread_books]\n",
    "\n",
    "    # Dự đoán điểm\n",
    "    with torch.no_grad():\n",
    "        user_tensor = torch.tensor([user_idx] * len(unread_book_indices), dtype=torch.long).to(device)\n",
    "        book_tensor = torch.tensor(unread_book_indices, dtype=torch.long).to(device)\n",
    "\n",
    "        preds = model(user_tensor, book_tensor).squeeze()\n",
    "\n",
    "        k = min(top_k, len(unread_books))\n",
    "        top_k_indices = torch.topk(preds, k).indices.cpu().numpy()\n",
    "\n",
    "    # Trả về danh sách top K dạng (book_id, score)\n",
    "    recommendations = []\n",
    "    for i in top_k_indices:\n",
    "        book_id = unread_books[i]\n",
    "        score = round(preds[i].item(), 3)\n",
    "        recommendations.append((book_id, score))\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fc5d063-e57f-4130-a8da-aa153ec58b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book ID: 1549 | Predicted rating: 5.321\n",
      "Book ID: 541 | Predicted rating: 5.303\n",
      "Book ID: 1581 | Predicted rating: 5.17\n",
      "Book ID: 1568 | Predicted rating: 5.117\n",
      "Book ID: 360 | Predicted rating: 5.083\n"
     ]
    }
   ],
   "source": [
    "top_books = recommend_books_for_user(\n",
    "    user_id=\"U056\",\n",
    "    model=model,\n",
    "    user2idx=user2idx,\n",
    "    book2idx=book2idx,\n",
    "    ratings_df=cbr,\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "for book, score in top_books:\n",
    "    print(f\"Book ID: {book} | Predicted rating: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a5f26ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lưu state_dict tại: checkpoints/ncf_state.pth\n"
     ]
    }
   ],
   "source": [
    "import os, datetime, torch\n",
    "\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "state_path = f\"checkpoints/ncf_state.pth\"\n",
    "full_path = f\"checkpoints/ncf_full.pth\"\n",
    "\n",
    "# Save only weights\n",
    "torch.save({ 'state_dict': model.state_dict() }, state_path)\n",
    "print(\"Lưu state_dict tại:\", state_path)\n",
    "\n",
    "# Save full model (architecture + weights).\n",
    "# This is less portable across code changes.\n",
    "# torch.save(model, full_path)\n",
    "# print(\"Saved full model to:\", full_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb901d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = 610          # thay bằng số user thực tế bạn dùng\n",
    "num_items = 9724         # thay bằng số item thực tế bạn dùng\n",
    "embedding_dim = 64\n",
    "hidden_layers = [128, 64, 32]\n",
    "\n",
    "model_loaded = NCF(num_users, num_items, embedding_dim, hidden_layers)\n",
    "\n",
    "# --- Bước 2: Load trọng số đã lưu ---\n",
    "ckpt = torch.load(\"checkpoints/ncf_state_YYYYMMDD_HHMMSS.pth\", map_location=\"cpu\")\n",
    "model_loaded.load_state_dict(ckpt[\"state_dict\"])\n",
    "model_loaded.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
